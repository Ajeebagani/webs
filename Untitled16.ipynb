{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd8998b-222e-48e8-8079-f442a6ccd3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      "['Natural Language Toolkit (NLTK) is one of the largest Python libraries for performing various Natural Language Processing tasks.', 'From rudimentary tasks such as text pre-processing to tasks likes vectorized representation of text – NLTK’s API has covered everything.']\n",
      "\n",
      "Word Tokenization:\n",
      "['Natural', 'Language', 'Toolkit', '(', 'NLTK', ')', 'is', 'one', 'of', 'the', 'largest', 'Python', 'libraries', 'for', 'performing', 'various', 'Natural', 'Language', 'Processing', 'tasks', '.', 'From', 'rudimentary', 'tasks', 'such', 'as', 'text', 'pre-processing', 'to', 'tasks', 'likes', 'vectorized', 'representation', 'of', 'text', '–', 'NLTK', '’', 's', 'API', 'has', 'covered', 'everything', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = \"Natural Language Toolkit (NLTK) is one of the largest Python libraries for performing various Natural Language Processing tasks. From rudimentary tasks such as text pre-processing to tasks likes vectorized representation of text – NLTK’s API has covered everything.\"\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\")\n",
    "print(sentences)\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcde2a1-00f1-4616-8378-a63279752944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text after removing stopwords:\n",
      "['Natural', 'Language', 'Toolkit', '(', 'NLTK', ')', 'works', 'powerful', 'Python', 'library', 'wide', 'range', 'tools', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '.', 'fundamental', 'tasks', 'like', 'text', 'pre-processing', 'advanced', 'operations', 'semantic', 'reasoning', ',', 'NLTK', 'provides', 'versatile', 'API', 'caters', 'diverse', 'needs', 'language-related', 'tasks', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text = \"Natural Language Toolkit (NLTK) works as a powerful Python library that a wide range of tools for Natural Language Processing (NLP). From fundamental tasks like text pre-processing to more advanced operations such as semantic reasoning, NLTK provides a versatile API that caters to the diverse needs of language-related tasks.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Text after removing stopwords:\")\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7978ae4-2e81-41b9-b50d-1fb9bd3334e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text after converting to lowercase and removing punctuation:\n",
      "let’s eat grandma grandma let’s eat silvia are you free tomorrow yes i’m free on saturday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "text = \"Let’s eat, Grandma! Grandma, Let’s eat! Silvia, Are you free tomorrow? Yes, I’m free on Saturday.\"\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "print(\"Text after converting to lowercase and removing punctuation:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f830309f-db36-4001-88ed-e1464073df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text:\n",
      "natural language processing nlp is a field of ai that focuses on enabling computers to understand language interpret generate human nlp includes tasks like tokenization lemmatization sentiment analysis it helps in applications such as chatbots machine translation and voice assistants however cleaning textremoving extra spaces punctuations special charactersis crucial without accurately preprocessing nlp models may not perform so can you clean this messy text make it structured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Given text\n",
    "text = \"\"\" @@Natural   Language Processing (NLP)!!!  is a    field of AI that  \n",
    "focuses on  ... enabling computers to understand, language.   \n",
    "interpret, & generate   human NLP   includes  tasks like **tokenization, lemmatization,**  && \n",
    "sentiment analysis. It helps in   applications such as chatbots,   machine translation,  \n",
    "and   voice assistants!!! However, cleaning text—removing   extra spaces, punctuations, && \n",
    "special $$$ characters—is crucial. Without accurately !!! preprocessing,  \n",
    "NLP models may not perform So, can you clean this   messy text & make  it    structured??? \"\"\"\n",
    "\n",
    "# Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Remove special characters and extra spaces\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "print(\"Cleaned Text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff4873f-047a-4704-bc15-ae1fb3381dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ajeeba\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words:\n",
      "['The', 'researchers', 'are', 'analyzing', 'various', 'datasets', 'to', 'study', 'the', 'effects', 'of', 'automation', '.', 'They', 'observed', 'that', 'automated', 'systems', 'perform', 'tasks', 'more', 'efficiently', 'than', 'humans', '.', 'Many', 'industries', 'have', 'been', 'adopting', 'AI-driven', 'solutions', 'to', 'improve', 'productivity', '.', 'Running', 'complex', 'algorithms', 'helps', 'in', 'predicting', 'future', 'trends', 'accurately', '.', 'Several', 'companies', 'are', 'investing', 'in', 'developing', 'smarter', 'and', 'more', 'adaptive', 'models', '.', 'Data', 'scientists', 'continuously', 'refine', 'their', 'models', 'to', 'achieve', 'better', 'performance', '.', 'The', 'advancements', 'in', 'technology', 'have', 'transformed', 'the', 'way', 'businesses', 'operate', '.']\n",
      "\n",
      "Stemmed Words:\n",
      "['the', 'research', 'are', 'analyz', 'variou', 'dataset', 'to', 'studi', 'the', 'effect', 'of', 'autom', '.', 'they', 'observ', 'that', 'autom', 'system', 'perform', 'task', 'more', 'effici', 'than', 'human', '.', 'mani', 'industri', 'have', 'been', 'adopt', 'ai-driven', 'solut', 'to', 'improv', 'product', '.', 'run', 'complex', 'algorithm', 'help', 'in', 'predict', 'futur', 'trend', 'accur', '.', 'sever', 'compani', 'are', 'invest', 'in', 'develop', 'smarter', 'and', 'more', 'adapt', 'model', '.', 'data', 'scientist', 'continu', 'refin', 'their', 'model', 'to', 'achiev', 'better', 'perform', '.', 'the', 'advanc', 'in', 'technolog', 'have', 'transform', 'the', 'way', 'busi', 'oper', '.']\n",
      "\n",
      "Lemmatized Words:\n",
      "['The', 'researcher', 'are', 'analyzing', 'various', 'datasets', 'to', 'study', 'the', 'effect', 'of', 'automation', '.', 'They', 'observed', 'that', 'automated', 'system', 'perform', 'task', 'more', 'efficiently', 'than', 'human', '.', 'Many', 'industry', 'have', 'been', 'adopting', 'AI-driven', 'solution', 'to', 'improve', 'productivity', '.', 'Running', 'complex', 'algorithm', 'help', 'in', 'predicting', 'future', 'trend', 'accurately', '.', 'Several', 'company', 'are', 'investing', 'in', 'developing', 'smarter', 'and', 'more', 'adaptive', 'model', '.', 'Data', 'scientist', 'continuously', 'refine', 'their', 'model', 'to', 'achieve', 'better', 'performance', '.', 'The', 'advancement', 'in', 'technology', 'have', 'transformed', 'the', 'way', 'business', 'operate', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Given text\n",
    "text = \"The researchers are analyzing various datasets to study the effects of automation. They observed that automated systems perform tasks more efficiently than humans. Many industries have been adopting AI-driven solutions to improve productivity. Running complex algorithms helps in predicting future trends accurately. Several companies are investing in developing smarter and more adaptive models. Data scientists continuously refine their models to achieve better performance. The advancements in technology have transformed the way businesses operate.\"\n",
    "\n",
    "# Tokenization\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Print results\n",
    "print(\"Original Words:\")\n",
    "print(words)\n",
    "print(\"\\nStemmed Words:\")\n",
    "print(stemmed_words)\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf88f8-3617-44a0-972c-eacad774a2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
